# ğŸš€ End-to-End Data Migration using Azure

This project showcases a full data pipeline migrating data from an on-premise SQL Server to Azure Synapse via Azure Data Factory, Data Lake, and Databricks.

---

## ğŸ§° Tech Stack

* **Azure Data Factory** â€“ Data ingestion & orchestration
* **Azure Key Vault** â€“ Secure credentials
* **Azure Data Lake Gen2** â€“ Data storage (Bronze/Silver/Gold)
* **Azure Databricks** â€“ Data transformation (PySpark + Delta)
* **Azure Synapse Analytics** â€“ Serverless SQL views for BI tools
* **SQL Server (SSMS)** â€“ Source data

---

## ğŸ—‚ï¸ Pipeline Overview

### ğŸ”¸ Ingestion (Bronze Layer)

* Lookup & ForEach in ADF fetches table metadata
* Data copied from on-prem SQL to Data Lake in Parquet format

### ğŸ”¹ Transformation (Silver & Gold Layers)

* Databricks notebooks mount storage and process data
* Bronze â Silver (cleaning), Silver â Gold (standardizing)

### ğŸŸ¡ Loading to Synapse

* Views created in Synapse via stored procedures
* Data is ready for Power BI or other BI tools

---

## âš™ï¸ Setup Summary

1. Set up resources: ADF, Databricks, Key Vault, Synapse, Storage
2. Create integration runtime and link services
3. Build ADF pipeline with Lookup â ForEach â Copy
4. Run Databricks notebooks for transformation
5. Use Synapse to expose Gold data as SQL views
6. Schedule daily runs via triggers

---

## ğŸ’µ Cost Estimate (INR)

| Service     | Estimate  |
| ----------- | --------- |
| ADF         | â‚¹186.75   |
| Databricks  | â‚¹1,992.00 |
| Storage     | â‚¹8.30     |
| Synapse SQL | â‚¹8.30     |
| **Total**   | â‚¹2,195.35 |

